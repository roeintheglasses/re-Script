# Environment Configuration for re-Script
# Copy this file to .env.local and fill in your values

# ==============================================
# Application Environment
# ==============================================
NODE_ENV=production

# ==============================================
# API Configuration
# ==============================================
# API server host and port
HOST=0.0.0.0
PORT=3001

# CORS configuration
CORS_ORIGIN=http://localhost:3000

# ==============================================
# Database & Cache Configuration
# ==============================================
# Redis URL for job queue and caching
REDIS_URL=redis://localhost:6379

# Optional: PostgreSQL for job persistence
# DATABASE_URL=postgresql://username:password@localhost:5432/rescript

# ==============================================
# LLM Provider Configuration
# ==============================================

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-api03-...

# OpenAI GPT
OPENAI_API_KEY=sk-...
OPENAI_ORG_ID=org-...

# Ollama (for local LLMs)
OLLAMA_BASE_URL=http://localhost:11434

# ==============================================
# File Processing Configuration
# ==============================================
# Maximum file size for uploads (in bytes)
MAX_FILE_SIZE=10485760  # 10MB

# Maximum number of files per job
MAX_FILES_PER_JOB=10

# Temporary file storage directory
TEMP_DIR=./tmp

# Processed file storage directory
OUTPUT_DIR=./uploads

# ==============================================
# Job Processing Configuration
# ==============================================
# Default job timeout (in milliseconds)
JOB_TIMEOUT=300000  # 5 minutes

# Maximum concurrent jobs
MAX_CONCURRENT_JOBS=5

# Job retry attempts
JOB_RETRY_ATTEMPTS=3

# ==============================================
# Security Configuration
# ==============================================
# Rate limiting
RATE_LIMIT_WINDOW_MS=900000  # 15 minutes
RATE_LIMIT_MAX_REQUESTS=100

# API key for authentication (optional)
API_KEY=

# JWT secret for session management (optional)
JWT_SECRET=

# ==============================================
# Logging Configuration
# ==============================================
# Log level (error, warn, info, debug)
LOG_LEVEL=info

# Log file directory
LOG_DIR=./logs

# Enable structured logging
STRUCTURED_LOGGING=true

# ==============================================
# Development Configuration
# ==============================================
# Enable Swagger API documentation
ENABLE_SWAGGER=false

# Enable debug mode
DEBUG=false

# Hot reload for development
HOT_RELOAD=false

# ==============================================
# Monitoring & Performance
# ==============================================
# Enable health check endpoint
ENABLE_HEALTH_CHECK=true

# Enable metrics collection
ENABLE_METRICS=true

# Metrics collection interval (in seconds)
METRICS_INTERVAL=60

# ==============================================
# Frontend Configuration (for Next.js)
# ==============================================
# Public API URL (accessible from browser)
NEXT_PUBLIC_API_URL=http://localhost:3001

# Enable analytics (optional)
NEXT_PUBLIC_ENABLE_ANALYTICS=false

# Analytics tracking ID
NEXT_PUBLIC_ANALYTICS_ID=

# ==============================================
# Docker Configuration
# ==============================================
# Container-specific overrides
HOSTNAME=0.0.0.0

# Volume mount paths
UPLOAD_VOLUME=/app/uploads
LOG_VOLUME=/app/logs

# ==============================================
# Advanced Configuration
# ==============================================
# Enable caching for LLM responses
ENABLE_LLM_CACHE=true

# Cache TTL (in seconds)
CACHE_TTL=3600  # 1 hour

# Enable request/response compression
ENABLE_COMPRESSION=true

# WebSocket configuration for real-time updates
WEBSOCKET_ENABLED=true
WEBSOCKET_PORT=3002

# ==============================================
# Provider-Specific Configuration
# ==============================================

# Anthropic Claude specific settings
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=4000
ANTHROPIC_TEMPERATURE=0.1

# OpenAI specific settings
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.1

# Ollama specific settings
OLLAMA_MODEL=llama2
OLLAMA_TIMEOUT=120000  # 2 minutes